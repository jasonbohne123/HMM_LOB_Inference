{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Inference of Hidden Markov Models on High Frequency Quote Data\n",
    "\n",
    "Benchmarking PSG performance of statistical inference against HMMLearn \n",
    "\n",
    "References:\n",
    "\n",
    "PSG: http://aorda.com/html/PSG_Help_HTML/index.html?hmm_normal.htm\n",
    "\n",
    "HMMLearn: https://hmmlearn.readthedocs.io/en/latest/index.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.add_dll_directory('C:\\Aorda\\PSG\\lib')\n",
    "import psgpython as psg \n",
    "from psg_loader import load_psg\n",
    "\n",
    "load_psg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputting features removing duplicated values within each observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 436 of original 15829 consecutive repeated values from input series\n",
      "Dropped 679 of original 15829 consecutive repeated values from input series\n",
      "Dropped 95 of original 15829 consecutive repeated values from input series\n",
      "Dropped 697 of original 15829 consecutive repeated values from input series\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features=pd.read_csv('data/grouped_features.csv',index_col=0)\n",
    "frac=0.75\n",
    "\n",
    "\n",
    "train_features=features[:np.floor(frac*features.shape[0]).astype(int)]\n",
    "test_features=features[np.floor(frac*features.shape[0]).astype(int):]\n",
    "\n",
    "def remove_duplicates(series):\n",
    "    \n",
    "    cleaned_series=series[np.insert(np.diff(series).astype(bool), 0, True)]\n",
    "    dropped_els=len(series)-len(cleaned_series)\n",
    "    \n",
    "    print(f\"Dropped {dropped_els} of original {len(series)} consecutive repeated values from input series\")\n",
    "    return cleaned_series\n",
    "\n",
    "bidsize=remove_duplicates(train_features['Bid_Size'].values)\n",
    "offersize=remove_duplicates(train_features['Offer_Size'].values)\n",
    "bookimbalance=remove_duplicates(train_features['OB_IB'].values)\n",
    "spread=remove_duplicates(train_features['spread'].values)\n",
    "\n",
    "# formatted as numpy float \n",
    "np.savetxt(r'psg_text_hmm/vector_bidsize.txt', bidsize)\n",
    "np.savetxt(r'psg_text_hmm/vector_offersize.txt', offersize)\n",
    "np.savetxt(r'psg_text_hmm/vector_bookimbalance.txt', bookimbalance)\n",
    "np.savetxt(r'psg_text_hmm/vector_spread.txt', spread)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bid_Size</th>\n",
       "      <th>Offer_Size</th>\n",
       "      <th>spread</th>\n",
       "      <th>OB_IB</th>\n",
       "      <th>last_spread</th>\n",
       "      <th>spread_state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:30:00</th>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.241429</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.589358</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:30:01</th>\n",
       "      <td>8.403670</td>\n",
       "      <td>7.559633</td>\n",
       "      <td>0.589358</td>\n",
       "      <td>2.472281</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:30:02</th>\n",
       "      <td>8.871795</td>\n",
       "      <td>5.051282</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>1.111623</td>\n",
       "      <td>0.166977</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:30:03</th>\n",
       "      <td>3.604651</td>\n",
       "      <td>3.604651</td>\n",
       "      <td>0.166977</td>\n",
       "      <td>1.873784</td>\n",
       "      <td>1.260233</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:30:04</th>\n",
       "      <td>5.348837</td>\n",
       "      <td>1.860465</td>\n",
       "      <td>1.260233</td>\n",
       "      <td>0.971420</td>\n",
       "      <td>0.344615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 14:34:02</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 14:34:03</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 14:34:05</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 14:34:08</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 14:34:09</th>\n",
       "      <td>1.812500</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>4.347917</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15829 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bid_Size  Offer_Size    spread      OB_IB  last_spread  \\\n",
       "sec                                                                           \n",
       "2020-01-02 09:30:00  1.142857    1.142857  0.241429   1.071429     0.589358   \n",
       "2020-01-02 09:30:01  8.403670    7.559633  0.589358   2.472281     0.058205   \n",
       "2020-01-02 09:30:02  8.871795    5.051282  0.058205   1.111623     0.166977   \n",
       "2020-01-02 09:30:03  3.604651    3.604651  0.166977   1.873784     1.260233   \n",
       "2020-01-02 09:30:04  5.348837    1.860465  1.260233   0.971420     0.344615   \n",
       "...                       ...         ...       ...        ...          ...   \n",
       "2020-01-02 14:34:02  2.000000   24.000000  0.010000  12.000000     0.010000   \n",
       "2020-01-02 14:34:03  3.500000   14.500000  0.010000  12.833333     0.010000   \n",
       "2020-01-02 14:34:05  2.000000    5.000000  0.010000   2.500000     0.010000   \n",
       "2020-01-02 14:34:08  4.000000    5.000000  0.010000   1.250000     0.017500   \n",
       "2020-01-02 14:34:09  1.812500    5.812500  0.017500   4.347917     0.030400   \n",
       "\n",
       "                     spread_state  \n",
       "sec                                \n",
       "2020-01-02 09:30:00            -1  \n",
       "2020-01-02 09:30:01             1  \n",
       "2020-01-02 09:30:02            -1  \n",
       "2020-01-02 09:30:03            -1  \n",
       "2020-01-02 09:30:04             1  \n",
       "...                           ...  \n",
       "2020-01-02 14:34:02             0  \n",
       "2020-01-02 14:34:03             0  \n",
       "2020-01-02 14:34:05             0  \n",
       "2020-01-02 14:34:08            -1  \n",
       "2020-01-02 14:34:09            -1  \n",
       "\n",
       "[15829 rows x 6 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "- Train HMM on one feature at a time\n",
    "- Assume each feature is sampled according to two normal distributions that are our hidden states. \n",
    "- Learn optimal parameterization of hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSG\n",
    "\n",
    "Utilized HMM_Normal optimization routine for each feature\n",
    "\n",
    "Initial point is estimated via Baum-Welch Algorithm\n",
    "\n",
    "Inference is completed via constrained optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Problem Imported\n",
      "\n",
      "Running solver\n",
      "Reading problem formulation\n",
      "Warning: 1 Object: Problem analizing\tMessage: Problem Statement: objective may be non-convex\n",
      "Asking for data information\n",
      "Getting data\n",
      "    100.0% of scenarios is processed\n",
      "100% of vector_spread was read\n",
      "Start optimization\n",
      "Ext.iteration=0  Objective=0.746387610616E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=10  Objective=0.746387610616E+00  Residual=0.000000000000E+00\n",
      "Optimization is stopped\n",
      "Solution is optimal\n",
      "Calculating resulting outputs. Writing solution.\n",
      "Objective: objective = 31117.1638666 [-4.342745230506E+16]\n",
      "Solver has normally finished. Solution was saved.\n",
      "Problem: problem_hmm_normal, solution_status = optimal\n",
      "Timing: data_loading_time = 0.08, preprocessing_time = 15.12, solving_time = 1.51\n",
      "Variables: optimal_point = point_problem_hmm_normal\n",
      "Objective: objective = 31117.1638666 [-4.342745230506E+16]\n",
      "Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states\n",
      "Function: hmm_normal(2,vector_spread) =  3.111716386665E+04\n",
      "OK. Solver Finished\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values(['problem_hmm_normal', 'optimal', ['problem_HMM_Normal, maximize', '  hmm_normal(2,vector_spread)', '  Solver: VAN , precision=9, stages=10'], ['Problem: problem_hmm_normal, solution_status = optimal', 'Timing: data_loading_time = 0.08, preprocessing_time = 15.12, solving_time = 1.51', 'Variables: optimal_point = point_problem_hmm_normal', 'Objective: objective = 31117.1638666 [-4.342745230506E+16]', 'Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states', 'Function: hmm_normal(2,vector_spread) =  3.111716386665E+04'], [['p1', 'p2', 'a1_1', 'a1_2', 'a2_1', 'a2_2', 'mu1', 'si1', 'mu2', 'si2'], array([0.        , 1.        , 0.92329517, 0.07670483, 0.56216745,\n",
       "       0.43783255, 0.03386868, 0.01370098, 0.5525988 , 1.09801273])], array([2., 2., 1., ..., 1., 1., 1.]), array([1., 1., 1.]), array([0.00000000e+00, 1.17683641e-14, 6.43929354e-15]), [['state1', 'state2'], array([[0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80466464, 0.19533536],\n",
       "       ...,\n",
       "       [0.99878061, 0.00121939],\n",
       "       [0.99739316, 0.00260684],\n",
       "       [0.99808398, 0.00191602]])], ['Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex'], ['Reading problem formulation', 'Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex', 'Asking for data information', 'Getting data', '    100.0% of scenarios is processed', '100% of vector_spread was read', 'Start optimization', 'Ext.iteration=0  Objective=0.746387610616E+00  Residual=0.000000000000E+00', 'Ext.iteration=10  Objective=0.746387610616E+00  Residual=0.000000000000E+00', 'Optimization is stopped', 'Solution is optimal', 'Calculating resulting outputs. Writing solution.', 'Objective: objective = 31117.1638666 [-4.342745230506E+16]', 'Solver has normally finished. Solution was saved.']])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_spread_prob = psg.psg_importfromtext('./psg_text_hmm/problem_hmm_normal_spread.txt')\n",
    "psg_spread_prob['problem_statement'] = '\\n'.join(psg_spread_prob['problem_statement'])\n",
    "spread_solution=psg.psg_solver(psg_spread_prob)\n",
    "spread_solution.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Problem Imported\n",
      "\n",
      "Running solver\n",
      "Reading problem formulation\n",
      "Warning: 1 Object: Problem analizing\tMessage: Problem Statement: objective may be non-convex\n",
      "Asking for data information\n",
      "Getting data\n",
      "    100.0% of scenarios is processed\n",
      "100% of vector_bookimbalance was read\n",
      "Start optimization\n",
      "Ext.iteration=0  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=17  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=33  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=50  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=65  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=81  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=98  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=112  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=131  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=144  Objective=0.550280448269E+00  Residual=0.000000000000E+00\n",
      "Optimization is stopped\n",
      "Solution is feasible\n",
      "Calculating resulting outputs. Writing solution.\n",
      "Objective: objective = -19076.7008834 [-0.433340420857]\n",
      "Solver has normally finished. Solution was saved.\n",
      "Problem: problem_hmm_normal, solution_status = feasible\n",
      "Timing: data_loading_time = 0.09, preprocessing_time = 15.46, solving_time = 18.52\n",
      "Variables: optimal_point = point_problem_hmm_normal\n",
      "Objective: objective = -19076.7008834 [-0.433340420857]\n",
      "Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states\n",
      "Function: hmm_normal(2,vector_bookimbalance) = -1.907670088342E+04\n",
      "OK. Solver Finished\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values(['problem_hmm_normal', 'feasible', ['problem_HMM_Normal, maximize', '  hmm_normal(2,vector_bookimbalance)', '  Solver: VAN , precision=9, stages=10'], ['Problem: problem_hmm_normal, solution_status = feasible', 'Timing: data_loading_time = 0.09, preprocessing_time = 15.46, solving_time = 18.52', 'Variables: optimal_point = point_problem_hmm_normal', 'Objective: objective = -19076.7008834 [-0.433340420857]', 'Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states', 'Function: hmm_normal(2,vector_bookimbalance) = -1.907670088342E+04'], [['p1', 'p2', 'a1_1', 'a1_2', 'a2_1', 'a2_2', 'mu1', 'si1', 'mu2', 'si2'], array([1.        , 0.        , 0.96627022, 0.03372978, 0.48776439,\n",
       "       0.51223561, 1.27015439, 0.61783865, 5.26742548, 5.86678499])], array([1., 1., 1., ..., 1., 1., 2.]), array([1., 1., 1.]), array([0.00000000e+00, 1.33226763e-14, 9.32587341e-15]), [['state1', 'state2'], array([[1.00000000e+00, 0.00000000e+00],\n",
       "       [9.88620821e-01, 1.13791792e-02],\n",
       "       [9.97888994e-01, 2.11100588e-03],\n",
       "       ...,\n",
       "       [5.53261247e-01, 4.46738753e-01],\n",
       "       [7.21791642e-01, 2.78208358e-01],\n",
       "       [8.21907083e-04, 9.99178093e-01]])], ['Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex'], ['Reading problem formulation', 'Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex', 'Asking for data information', 'Getting data', '    100.0% of scenarios is processed', '100% of vector_bookimbalance was read', 'Start optimization', 'Ext.iteration=0  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=17  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=33  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=50  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=65  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=81  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=98  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=112  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=131  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Ext.iteration=144  Objective=0.550280448269E+00  Residual=0.000000000000E+00', 'Optimization is stopped', 'Solution is feasible', 'Calculating resulting outputs. Writing solution.', 'Objective: objective = -19076.7008834 [-0.433340420857]', 'Solver has normally finished. Solution was saved.']])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_bookimbalance_prob = psg.psg_importfromtext('./psg_text_hmm/problem_hmm_normal_bookimbalance.txt')\n",
    "psg_bookimbalance_prob['problem_statement'] = '\\n'.join(psg_bookimbalance_prob['problem_statement'])\n",
    "bookimbalance_solution=psg.psg_solver(psg_bookimbalance_prob)\n",
    "bookimbalance_solution.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offer Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Problem Imported\n",
      "\n",
      "Running solver\n",
      "Reading problem formulation\n",
      "Warning: 1 Object: Problem analizing\tMessage: Problem Statement: objective may be non-convex\n",
      "Asking for data information\n",
      "Getting data\n",
      "    100.0% of scenarios is processed\n",
      "100% of vector_offersize was read\n",
      "Start optimization\n",
      "Ext.iteration=0  Objective=0.640663347363E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=47  Objective=0.640663347363E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=94  Objective=0.640663347363E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=142  Objective=0.640663347364E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=144  Objective=0.640663347364E+00  Residual=0.000000000000E+00\n",
      "Optimization is stopped\n",
      "Solution is feasible\n",
      "Calculating resulting outputs. Writing solution.\n",
      "Objective: objective = -22506.9342039 [-0.439133406798]\n",
      "Solver has normally finished. Solution was saved.\n",
      "Problem: problem_hmm_normal, solution_status = feasible\n",
      "Timing: data_loading_time = 0.05, preprocessing_time = 8.04, solving_time = 6.34\n",
      "Variables: optimal_point = point_problem_hmm_normal\n",
      "Objective: objective = -22506.9342039 [-0.439133406798]\n",
      "Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states\n",
      "Function: hmm_normal(2,vector_offersize) = -2.250693420394E+04\n",
      "OK. Solver Finished\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values(['problem_hmm_normal', 'feasible', ['problem_HMM_Normal, maximize', '  hmm_normal(2,vector_offersize)', '  Solver: VAN , precision=9, stages=10'], ['Problem: problem_hmm_normal, solution_status = feasible', 'Timing: data_loading_time = 0.05, preprocessing_time = 8.04, solving_time = 6.34', 'Variables: optimal_point = point_problem_hmm_normal', 'Objective: objective = -22506.9342039 [-0.439133406798]', 'Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states', 'Function: hmm_normal(2,vector_offersize) = -2.250693420394E+04'], [['p1', 'p2', 'a1_1', 'a1_2', 'a2_1', 'a2_2', 'mu1', 'si1', 'mu2', 'si2'], array([0.        , 1.        , 0.96486587, 0.03513413, 0.37422167,\n",
       "       0.62577833, 2.1656628 , 0.75128616, 7.89900263, 8.40985197])], array([2., 2., 2., ..., 2., 2., 2.]), array([1., 1., 1.]), array([1.82853732e-13, 1.19904087e-14, 3.55271368e-15]), [['state1', 'state2'], array([[0.00000000e+00, 1.00000000e+00],\n",
       "       [3.33684060e-12, 1.00000000e+00],\n",
       "       [8.56285664e-03, 9.91437143e-01],\n",
       "       ...,\n",
       "       [1.53291059e-59, 1.00000000e+00],\n",
       "       [3.24387546e-04, 9.99675612e-01],\n",
       "       [5.35505398e-05, 9.99946449e-01]])], ['Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex'], ['Reading problem formulation', 'Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex', 'Asking for data information', 'Getting data', '    100.0% of scenarios is processed', '100% of vector_offersize was read', 'Start optimization', 'Ext.iteration=0  Objective=0.640663347363E+00  Residual=0.000000000000E+00', 'Ext.iteration=47  Objective=0.640663347363E+00  Residual=0.000000000000E+00', 'Ext.iteration=94  Objective=0.640663347363E+00  Residual=0.000000000000E+00', 'Ext.iteration=142  Objective=0.640663347364E+00  Residual=0.000000000000E+00', 'Ext.iteration=144  Objective=0.640663347364E+00  Residual=0.000000000000E+00', 'Optimization is stopped', 'Solution is feasible', 'Calculating resulting outputs. Writing solution.', 'Objective: objective = -22506.9342039 [-0.439133406798]', 'Solver has normally finished. Solution was saved.']])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_offersize_prob = psg.psg_importfromtext('./psg_text_hmm/problem_hmm_normal_offersize.txt')\n",
    "psg_offersize_prob['problem_statement'] = '\\n'.join(psg_offersize_prob['problem_statement'])\n",
    "offersize_solution=psg.psg_solver(psg_offersize_prob)\n",
    "offersize_solution.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bid Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Problem Imported\n",
      "\n",
      "Running solver\n",
      "Reading problem formulation\n",
      "Warning: 1 Object: Problem analizing\tMessage: Problem Statement: objective may be non-convex\n",
      "Asking for data information\n",
      "Getting data\n",
      "    100.0% of scenarios is processed\n",
      "100% of vector_bidsize was read\n",
      "Start optimization\n",
      "Ext.iteration=0  Objective=0.573682602654E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=50  Objective=0.573682602654E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=99  Objective=0.573682602654E+00  Residual=0.000000000000E+00\n",
      "Ext.iteration=144  Objective=0.573682602654E+00  Residual=0.000000000000E+00\n",
      "Optimization is stopped\n",
      "Solution is feasible\n",
      "Calculating resulting outputs. Writing solution.\n",
      "Objective: objective = -22767.6679717 [-0.496085898942]\n",
      "Solver has normally finished. Solution was saved.\n",
      "Problem: problem_hmm_normal, solution_status = feasible\n",
      "Timing: data_loading_time = 0.07, preprocessing_time = 8.03, solving_time = 6.14\n",
      "Variables: optimal_point = point_problem_hmm_normal\n",
      "Objective: objective = -22767.6679717 [-0.496085898942]\n",
      "Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states\n",
      "Function: hmm_normal(2,vector_bidsize) = -2.276766797166E+04\n",
      "OK. Solver Finished\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values(['problem_hmm_normal', 'feasible', ['problem_HMM_Normal, maximize', '  hmm_normal(2,vector_bidsize)', '  Solver: VAN , precision=9, stages=10'], ['Problem: problem_hmm_normal, solution_status = feasible', 'Timing: data_loading_time = 0.07, preprocessing_time = 8.03, solving_time = 6.14', 'Variables: optimal_point = point_problem_hmm_normal', 'Objective: objective = -22767.6679717 [-0.496085898942]', 'Constraint: sum_of_probabilities_for_states = vector_sum_of_probabilities_for_states', 'Function: hmm_normal(2,vector_bidsize) = -2.276766797166E+04'], [['p1', 'p2', 'a1_1', 'a1_2', 'a2_1', 'a2_2', 'mu1', 'si1', 'mu2', 'si2'], array([0.        , 1.        , 0.94899043, 0.05100957, 0.39987896,\n",
       "       0.60012104, 2.24465004, 0.72511467, 5.76143998, 4.8864252 ])], array([2., 2., 2., ..., 1., 1., 1.]), array([1., 1., 1.]), array([0.00000000e+00, 7.32747196e-15, 4.66293670e-15]), [['state1', 'state2'], array([[0.00000000e+00, 1.00000000e+00],\n",
       "       [9.52712471e-17, 1.00000000e+00],\n",
       "       [9.59071719e-19, 1.00000000e+00],\n",
       "       ...,\n",
       "       [9.89946478e-01, 1.00535222e-02],\n",
       "       [9.28738545e-01, 7.12614551e-02],\n",
       "       [9.82188364e-01, 1.78116358e-02]])], ['Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex'], ['Reading problem formulation', 'Warning: 1 Object: Problem analizing\\tMessage: Problem Statement: objective may be non-convex', 'Asking for data information', 'Getting data', '    100.0% of scenarios is processed', '100% of vector_bidsize was read', 'Start optimization', 'Ext.iteration=0  Objective=0.573682602654E+00  Residual=0.000000000000E+00', 'Ext.iteration=50  Objective=0.573682602654E+00  Residual=0.000000000000E+00', 'Ext.iteration=99  Objective=0.573682602654E+00  Residual=0.000000000000E+00', 'Ext.iteration=144  Objective=0.573682602654E+00  Residual=0.000000000000E+00', 'Optimization is stopped', 'Solution is feasible', 'Calculating resulting outputs. Writing solution.', 'Objective: objective = -22767.6679717 [-0.496085898942]', 'Solver has normally finished. Solution was saved.']])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_bidsize_prob = psg.psg_importfromtext('./psg_text_hmm/problem_hmm_normal_bidsize.txt')\n",
    "psg_bidsize_prob['problem_statement'] = '\\n'.join(psg_bidsize_prob['problem_statement'])\n",
    "bidsize_solution=psg.psg_solver(psg_bidsize_prob)\n",
    "bidsize_solution.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Learn\n",
    "\n",
    "\n",
    "- Set 2 hidden components\n",
    "- Solves via the Viterbi Forward Backwards Algorithm\n",
    "- Full covariance matrix with min_covar to prevent overfitting\n",
    "- Tolerance set equivantly to PSG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -74496.5604             +nan\n",
      "         2       11313.9291      +85810.4895\n",
      "         3       21624.1755      +10310.2464\n",
      "         4       27094.1741       +5469.9986\n",
      "         5       29533.0020       +2438.8279\n",
      "         6       30497.0739        +964.0719\n",
      "         7       30894.9109        +397.8370\n",
      "         8       31041.5028        +146.5919\n",
      "         9       31091.0698         +49.5670\n",
      "        10       31107.7729         +16.7031\n",
      "        11       31113.5686          +5.7957\n",
      "        12       31115.6614          +2.0928\n",
      "        13       31116.4565          +0.7951\n",
      "        14       31116.7786          +0.3221\n",
      "        15       31116.9190          +0.1404\n",
      "        16       31116.9849          +0.0659\n",
      "        17       31117.0179          +0.0330\n",
      "        18       31117.0353          +0.0174\n",
      "        19       31117.0448          +0.0095\n",
      "        20       31117.0500          +0.0053\n",
      "        21       31117.0530          +0.0030\n",
      "        22       31117.0547          +0.0017\n",
      "        23       31117.0557          +0.0010\n",
      "        24       31117.0562          +0.0006\n",
      "        25       31117.0566          +0.0003\n",
      "        26       31117.0568          +0.0002\n",
      "        27       31117.0569          +0.0001\n",
      "        28       31117.0569          +0.0001\n",
      "        29       31117.0570          +0.0000\n",
      "        30       31117.0570          +0.0000\n",
      "        31       31117.0570          +0.0000\n",
      "        32       31117.0570          +0.0000\n",
      "        33       31117.0570          +0.0000\n",
      "        34       31117.0570          +0.0000\n",
      "        35       31117.0570          +0.0000\n",
      "        36       31117.0570          +0.0000\n",
      "        37       31117.0570          +0.0000\n",
      "        38       31117.0570          +0.0000\n",
      "        39       31117.0570          +0.0000\n",
      "        40       31117.0570          +0.0000\n",
      "        41       31117.0570          +0.0000\n",
      "        42       31117.0570          +0.0000\n",
      "        43       31117.0570          +0.0000\n",
      "        44       31117.0570          +0.0000\n"
     ]
    }
   ],
   "source": [
    "spread_model=GaussianHMM(n_components=2,algorithm='viterbi',covariance_type=\"spherical\",min_covar=1e-4, n_iter=1000,tol=1e-8, verbose=True)\n",
    "fitted_spread_model=spread_model.fit(spread.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix is [0.92348119 0.07651881 0.56258625 0.43741375]\n",
      "Mean Values are is [0.03388608 0.55392045]\n",
      "Covariance Matrix is [1.89240669e-04 1.20837905e+00]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transition Matrix is {fitted_spread_model.transmat_.flatten()}\")\n",
    "print(f\"Mean Values are is {fitted_spread_model.means_.flatten()}\")\n",
    "print(f\"Covariance Matrix is {fitted_spread_model.covars_.flatten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -36170.8174             +nan\n",
      "         2      -21928.1596      +14242.6579\n",
      "         3      -19815.2928       +2112.8668\n",
      "         4      -19287.1485        +528.1443\n",
      "         5      -19149.2612        +137.8873\n",
      "         6      -19101.5593         +47.7019\n",
      "         7      -19085.1258         +16.4334\n",
      "         8      -19079.5451          +5.5807\n",
      "         9      -19077.6607          +1.8844\n",
      "        10      -19077.0251          +0.6356\n",
      "        11      -19076.8105          +0.2145\n",
      "        12      -19076.7380          +0.0725\n",
      "        13      -19076.7135          +0.0245\n",
      "        14      -19076.7052          +0.0083\n",
      "        15      -19076.7023          +0.0028\n",
      "        16      -19076.7014          +0.0010\n",
      "        17      -19076.7011          +0.0003\n",
      "        18      -19076.7009          +0.0001\n",
      "        19      -19076.7009          +0.0000\n",
      "        20      -19076.7009          +0.0000\n",
      "        21      -19076.7009          +0.0000\n",
      "        22      -19076.7009          +0.0000\n",
      "        23      -19076.7009          +0.0000\n",
      "        24      -19076.7009          +0.0000\n",
      "        25      -19076.7009          +0.0000\n",
      "        26      -19076.7009          +0.0000\n",
      "        27      -19076.7009          +0.0000\n"
     ]
    }
   ],
   "source": [
    "bookimbalance_model=GaussianHMM(n_components=2,algorithm='viterbi',covariance_type=\"spherical\",min_covar=1e-4, n_iter=1000,tol=1e-8, verbose=True)\n",
    "fitted_bookimbalance_model=bookimbalance_model.fit(bookimbalance.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix is [0.96627036 0.03372964 0.48776422 0.51223578]\n",
      "Mean Values are is [1.27015475 5.26743463]\n",
      "Covariance Matrix is [ 0.3817259  34.41927375]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transition Matrix is {fitted_bookimbalance_model.transmat_.flatten()}\")\n",
    "print(f\"Mean Values are is {fitted_bookimbalance_model.means_.flatten()}\")\n",
    "print(f\"Covariance Matrix is {fitted_bookimbalance_model.covars_.flatten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bid Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -37020.3760             +nan\n",
      "         2      -24164.7227      +12855.6532\n",
      "         3      -23358.2629        +806.4598\n",
      "         4      -23037.8171        +320.4458\n",
      "         5      -22901.8110        +136.0061\n",
      "         6      -22836.5719         +65.2391\n",
      "         7      -22802.8371         +33.7348\n",
      "         8      -22785.4744         +17.3627\n",
      "         9      -22776.8232          +8.6512\n",
      "        10      -22772.6350          +4.1882\n",
      "        11      -22770.6330          +2.0020\n",
      "        12      -22769.6396          +0.9933\n",
      "        13      -22769.0270          +0.6126\n",
      "        14      -22768.4863          +0.5407\n",
      "        15      -22768.0436          +0.4427\n",
      "        16      -22767.8065          +0.2370\n",
      "        17      -22767.7153          +0.0912\n",
      "        18      -22767.6844          +0.0309\n",
      "        19      -22767.6739          +0.0104\n",
      "        20      -22767.6703          +0.0037\n",
      "        21      -22767.6689          +0.0014\n",
      "        22      -22767.6684          +0.0005\n",
      "        23      -22767.6681          +0.0002\n",
      "        24      -22767.6680          +0.0001\n",
      "        25      -22767.6680          +0.0000\n",
      "        26      -22767.6680          +0.0000\n",
      "        27      -22767.6680          +0.0000\n",
      "        28      -22767.6680          +0.0000\n",
      "        29      -22767.6680          +0.0000\n",
      "        30      -22767.6680          +0.0000\n",
      "        31      -22767.6680          +0.0000\n",
      "        32      -22767.6680          +0.0000\n",
      "        33      -22767.6680          +0.0000\n",
      "        34      -22767.6680          +0.0000\n",
      "        35      -22767.6680          +0.0000\n",
      "        36      -22767.6680          +0.0000\n"
     ]
    }
   ],
   "source": [
    "bidsize_model=GaussianHMM(n_components=2,algorithm='viterbi',covariance_type=\"spherical\",min_covar=1e-4, n_iter=1000,tol=1e-8, verbose=True)\n",
    "fitted_bidsize_model=bidsize_model.fit(bidsize.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix is [0.94899063 0.05100937 0.3998793  0.6001207 ]\n",
      "Mean Values are is [2.24465083 5.76144924]\n",
      "Covariance Matrix is [ 0.5257934  23.87723822]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transition Matrix is {fitted_bidsize_model.transmat_.flatten()}\")\n",
    "print(f\"Mean Values are is {fitted_bidsize_model.means_.flatten()}\")\n",
    "print(f\"Covariance Matrix is {fitted_bidsize_model.covars_.flatten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offer Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -100805.2281             +nan\n",
      "         2      -26409.6368      +74395.5913\n",
      "         3      -23642.1305       +2767.5063\n",
      "         4      -22801.6824        +840.4481\n",
      "         5      -22592.3205        +209.3619\n",
      "         6      -22534.3155         +58.0050\n",
      "         7      -22516.4261         +17.8894\n",
      "         8      -22510.6892          +5.7369\n",
      "         9      -22508.8512          +1.8380\n",
      "        10      -22508.2678          +0.5834\n",
      "        11      -22508.0840          +0.1838\n",
      "        12      -22508.0264          +0.0576\n",
      "        13      -22508.0084          +0.0180\n",
      "        14      -22508.0028          +0.0056\n",
      "        15      -22508.0011          +0.0018\n",
      "        16      -22508.0005          +0.0005\n",
      "        17      -22508.0004          +0.0002\n",
      "        18      -22508.0003          +0.0001\n",
      "        19      -22508.0003          +0.0000\n",
      "        20      -22508.0003          +0.0000\n",
      "        21      -22508.0003          +0.0000\n",
      "        22      -22508.0003          +0.0000\n",
      "        23      -22508.0003          +0.0000\n",
      "        24      -22508.0003          +0.0000\n",
      "        25      -22508.0003          +0.0000\n",
      "        26      -22508.0003          +0.0000\n"
     ]
    }
   ],
   "source": [
    "offersize_model=GaussianHMM(n_components=2,algorithm='viterbi',covariance_type=\"spherical\",min_covar=1e-4, n_iter=1000,tol=1e-8, verbose=True)\n",
    "fitted_offersize_model=offersize_model.fit(offersize.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix is [0.96476318 0.03523682 0.37490105 0.62509895]\n",
      "Mean Values are is [2.16556749 7.9049774 ]\n",
      "Covariance Matrix is [ 0.56440982 70.746429  ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transition Matrix is {fitted_offersize_model.transmat_.flatten()}\")\n",
    "print(f\"Mean Values are is {fitted_offersize_model.means_.flatten()}\")\n",
    "print(f\"Covariance Matrix is {fitted_offersize_model.covars_.flatten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationary Distributions\n",
    "\n",
    "Limiting marginal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary Distribution for Spread HMM is [0.88027194 0.11972806]\n",
      "Stationary Distribution for Book Imbalance HMM is [0.93532112 0.06467888]\n",
      "Stationary Distribution for Bidsize HMM is [0.88686926 0.11313074]\n",
      "Stationary Distribution for Offersize HMM is [0.91408543 0.08591457]\n"
     ]
    }
   ],
   "source": [
    "spread_stationary=fitted_spread_model.get_stationary_distribution()\n",
    "bookimbalance_stationary=fitted_bookimbalance_model.get_stationary_distribution()\n",
    "bidsize_stationary=fitted_bidsize_model.get_stationary_distribution()\n",
    "offersize_stationary=fitted_offersize_model.get_stationary_distribution()\n",
    "\n",
    "print(f\"Stationary Distribution for Spread HMM is {spread_stationary}\")\n",
    "print(f\"Stationary Distribution for Book Imbalance HMM is {bookimbalance_stationary}\")\n",
    "print(f\"Stationary Distribution for Bidsize HMM is {bidsize_stationary}\")\n",
    "print(f\"Stationary Distribution for Offersize HMM is {offersize_stationary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of Sample Validation and Scoring\n",
    "\n",
    "Given a test set we can score performance of PSG trained model and HMMLearn trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_pred=fitted_spread_model.predict(test_features['spread'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookimbalance_pred=fitted_bookimbalance_model.predict(test_features['OB_IB'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidsize_pred=fitted_bidsize_model.predict(test_features['Bid_Size'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "offersize_pred=fitted_offersize_model.predict(test_features['Offer_Size'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual evaluation can be computed as a T test on the sample coming from either distribution. Reject or do not reject at $\\alpha$ confidence level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('hmm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80cc58d642badbeb27aa4dea55477ea0db095f88739fbd6a40ddef87b59ea8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
